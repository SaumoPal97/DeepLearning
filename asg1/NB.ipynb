{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "# import train\n",
    "from IPython.display import display\n",
    "import pickle\n",
    "from main import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes:  (60000L, 28L, 28L, 1L) (60000L,) (10000L, 28L, 28L, 1L) (10000L,)\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(suppress=True, precision=6)\n",
    "\n",
    "# Training error - Manual for NB\n",
    "trainX, trainY, testX, testY = load_mnist()\n",
    "print \"Shapes: \", trainX.shape, trainY.shape, testX.shape, testY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softmax(vec):\n",
    "    evec = np.exp(vec - np.max(vec))\n",
    "    s = np.sum(evec)\n",
    "    return evec/s\n",
    "\n",
    "def sigmoid(vec):\n",
    "    evec = 1 + np.exp(-vec)\n",
    "    return 1/evec\n",
    "\n",
    "def test(testX):\n",
    "    '''\n",
    "    Complete this function.\n",
    "    This function must read the weight files and\n",
    "    return the predicted labels.\n",
    "    The returned object must be a 1-dimensional numpy array of\n",
    "    length equal to the number of examples. The i-th element\n",
    "    of the array should contain the label of the i-th test\n",
    "    example.\n",
    "    '''\n",
    "    w1 = np.loadtxt('weights/w1.csv', delimiter=',')\n",
    "    w2 = np.loadtxt('weights/w2.csv', delimiter=',')\n",
    "    \n",
    "    sampleCount = testX.shape[0]\n",
    "    \n",
    "    \n",
    "    x = np.ndarray((sampleCount, 28*28))\n",
    "    for sample in range(sampleCount):\n",
    "        x[sample, :] = np.reshape(testX[sample, :], 28*28)\n",
    "    x = np.concatenate((np.ones((sampleCount, 1)), x), axis = 1)\n",
    "    \n",
    "    y = np.zeros(testX.shape[0])\n",
    "    \n",
    "    for sample in range(sampleCount):\n",
    "        xi = np.ndarray((1, 785))\n",
    "        xi[0,:] = np.transpose(x[sample, :])\n",
    "        h = sigmoid(np.matmul(xi, w1))\n",
    "        h = np.concatenate((np.ones((1, 1)), h), axis = 1)\n",
    "        yi = np.matmul(h, w2).transpose()\n",
    "        pi = softmax(yi)\n",
    "        y[sample] = np.argmax(pi)\n",
    "    return y\n",
    "\n",
    "def train(trainX, trainY):\n",
    "    '''\n",
    "    Complete this function.\n",
    "    '''\n",
    "    print('Initializing...')\n",
    "\n",
    "    eta_1 = 0.01\n",
    "    eta_2 = eta_1\n",
    "    sampleCount = trainX.shape[0]\n",
    "    \n",
    "    hidden_layer_size = 800\n",
    "    hidden_layer = np.array([0]*hidden_layer_size)\n",
    "\n",
    "    x = np.ndarray((sampleCount, 28*28))\n",
    "    for sample in range(sampleCount):\n",
    "        x[sample, :] = np.reshape(trainX[sample, :], 28*28)\n",
    "    x = np.concatenate((np.ones((sampleCount, 1)), x), axis = 1)\n",
    "\n",
    "    N1 = 28*28 + 1\n",
    "    w1 = np.random.rand(N1, hidden_layer_size)/100000\n",
    "\n",
    "    N2 = 10\n",
    "    w2 = np.random.rand(hidden_layer_size + 1, N2)/100000\n",
    "\n",
    "    epochs = 50\n",
    "    for ep in range(epochs):\n",
    "        batch_size = 300\n",
    "        for zz in range(trainX.shape[0]/batch_size):\n",
    "            sampleSet = range(zz*batch_size, min(trainX.shape[0], zz*batch_size + batch_size))\n",
    "            small_x = np.ndarray((batch_size, 785))\n",
    "            small_x[:,:] = x[sampleSet, :]\n",
    "            \n",
    "            h = sigmoid(np.dot(small_x, w1))\n",
    "            h = np.concatenate((np.ones((batch_size,1)), h), axis = 1)\n",
    "            \n",
    "            y = np.dot(h, w2)\n",
    "            \n",
    "            p = np.apply_along_axis(softmax, 1, y)\n",
    "            t_all = trainY[sampleSet]\n",
    "            \n",
    "            grad1 = p.copy()\n",
    "            grad1[range(batch_size), t_all] -= 1\n",
    "            \n",
    "            \n",
    "            delW2 = np.matmul(h.transpose(), grad1)\n",
    "            temp0 = np.matmul(grad1, w2.transpose())\n",
    "            temp1 = (h*(1-h))*temp0\n",
    "            delW1 = np.dot(small_x.transpose(), temp1)[:, 1:]\n",
    "        \n",
    "            w1 = w1 - eta_1*delW1/batch_size\n",
    "            w2 = w2 - eta_2*delW2/batch_size\n",
    "        print 'Epoch: ', ep        \n",
    "        np.savetxt('weights/w1.csv', w1, delimiter=',')\n",
    "        np.savetxt('weights/w2.csv', w2, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing...\n",
      "Epoch:  0\n",
      "Epoch:  1\n",
      "Epoch:  2\n",
      "Epoch:  3\n",
      "Epoch:  4\n",
      "Epoch:  5\n",
      "Epoch:  6\n",
      "Epoch:  7\n",
      "Epoch:  8\n",
      "Epoch:  9\n",
      "Epoch:  10\n",
      "Epoch:  11\n",
      "Epoch:  12\n",
      "Epoch:  13\n",
      "Epoch:  14\n",
      "Epoch:  15\n",
      "Epoch:  16\n",
      "Epoch:  17\n",
      "Epoch:  18\n",
      "Epoch:  19\n",
      "Epoch:  20\n",
      "Epoch:  21\n",
      "Epoch:  22\n",
      "Epoch:  23\n",
      "Epoch:  24\n",
      "Epoch:  25\n",
      "Epoch:  26\n",
      "Epoch:  27\n",
      "Epoch:  28\n",
      "Epoch:  29\n",
      "Epoch:  30\n",
      "Epoch:  31\n",
      "Epoch:  32\n",
      "Epoch:  33\n",
      "Epoch:  34\n",
      "Epoch:  35\n",
      "Epoch:  36\n",
      "Epoch:  37\n",
      "Epoch:  38\n",
      "Epoch:  39\n",
      "Epoch:  40\n",
      "Epoch:  41\n",
      "Epoch:  42\n",
      "Epoch:  43\n",
      "Epoch:  44\n",
      "Epoch:  45\n",
      "Epoch:  46\n",
      "Epoch:  47\n",
      "Epoch:  48\n",
      "Epoch:  49\n",
      "\n",
      "Test accuracy: 97.110000%\n"
     ]
    }
   ],
   "source": [
    "# print \"\\nDigit sample\"\n",
    "# print_digit(trainX[1], trainY[1])\n",
    "\n",
    "train(trainX, trainY)\n",
    "\n",
    "labels = test(testX)\n",
    "accuracy = np.mean((labels == testY)) * 100.0\n",
    "print \"\\nTest accuracy: %lf%%\" % accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train accuracy: 93.570000%\n"
     ]
    }
   ],
   "source": [
    "labels = test(testX)\n",
    "accuracy = np.mean((labels == testY)) * 100.0\n",
    "print \"\\nTrain accuracy: %lf%%\" % accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "       [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "       [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "       ..., \n",
       "       [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "       [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "       [ nan,  nan,  nan, ...,  nan,  nan,  nan]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "       [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "       [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "       ..., \n",
       "       [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "       [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "       [ nan,  nan,  nan, ...,  nan,  nan,  nan]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "w1 = np.loadtxt('weights/w1.csv', delimiter=',')\n",
    "w2 = np.loadtxt('weights/w2.csv', delimiter=',')\n",
    "\n",
    "display(w1)\n",
    "\n",
    "display(w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.000455, -0.000302,  0.000002, ..., -0.001047,  0.000743,\n",
       "         0.000018],\n",
       "       [ 0.000006,  0.000001,  0.000036, ...,  0.00008 ,  0.000074,\n",
       "         0.000072],\n",
       "       [ 0.000053,  0.000076,  0.000037, ...,  0.000067,  0.000075,\n",
       "         0.000056],\n",
       "       ..., \n",
       "       [ 0.000067,  0.000079,  0.000077, ...,  0.000079,  0.000052,\n",
       "         0.000018],\n",
       "       [ 0.000077,  0.00004 ,  0.000085, ...,  0.000062,  0.000008,\n",
       "         0.000021],\n",
       "       [ 0.000058,  0.000062,  0.000097, ...,  0.000077,  0.000045,\n",
       "         0.000031]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
